{"componentChunkName":"component---src-templates-lesson-template-js","path":"/intro-complexity","result":{"data":{"markdownRemark":{"html":"<p>Ok so till now we have just learn some algorithm and tried to solve some problems based on them. Now an important question arise while programming is: How efficient is an algorithm or piece of code? How much time and space does it take to run?</p>\n<h2 id=\"what-is-complexity-analysis\" style=\"position:relative;\"><a href=\"#what-is-complexity-analysis\" aria-label=\"what is complexity analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>What is Complexity analysis</em></h2>\n<p>It's really important to understand the real-world significance of <strong>algorithms and its properties</strong> because using different ideas one can design many algorithms for computing a solution to a given problem. Key important questions in algorithms are :</p>\n<ul>\n<li>How do we design <strong>good</strong> algorithms?</li>\n<li>How do we know that our algorithm is <strong>efficient</strong>?</li>\n<li>How to efficiently implement algorithms in a programming language?</li>\n</ul>\n<blockquote>\n<p><strong>Interviewer</strong> <em>often checks your ideas and coding skills by asking you to write a code giving restrictions on its</em> <strong>time or space complexities.</strong></p>\n</blockquote>\n<h2 id=\"why-to-do-complexity-analysis\" style=\"position:relative;\"><a href=\"#why-to-do-complexity-analysis\" aria-label=\"why to do complexity analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Why to do Complexity analysis</em></h2>\n<p>We already know there are tools to measure how fast a program runs. There are programs called <em>profilers</em> which measure running time in milliseconds and can help us optimize our code by spotting bottlenecks. While this is a useful tool, it isn't really relevant to algorithm complexity. Algorithm complexity is something designed to compare two algorithms at the idea level ‚Äî ignoring low-level details such as the implementation programming language, the hardware the algorithm runs on, or the instruction set of the given CPU. We want to compare algorithms in terms of just what they are: Ideas of how something is computed. Counting milliseconds won't help us in that. It's quite possible that a bad algorithm written in a low-level programming language such as <a href=\"http://en.wikipedia.org/wiki/Assembly_language\">assembly</a> runs much quicker than a good algorithm written in a high-level programming language such as <a href=\"http://www.python.org/\">Python</a> or <a href=\"http://www.ruby-lang.org/en/\">Ruby</a>.</p>\n<h3 id=\"memory\" style=\"position:relative;\"><a href=\"#memory\" aria-label=\"memory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Memory</em></h3>\n<p>Memory in a computer is just a sequential set of \"buckets\" that can contain numbers, characters, or Boolean values. By using several buckets in a row, we get arrays. By giving names to a set of contiguous buckets, we get a \"structure\". But at its core, a computer memory is a very simple list of numbers. Everything else must be built up upon this.</p>\n<ol>\n<li>\n<p>Memory is laid out in sequential order basically from 0 on up (one byte at a time). Each position in memory has a number (called its address!).</p>\n</li>\n<li>\n<p>The compiler (or interpreter) associates your variable names with memory addresses.</p>\n</li>\n<li>\n<p>In some languages like C, you can actually ask the computer for the address of a variable in memory. In C this is done using the ampersand &#x26;</p>\n<p>In many languages, the actual address is hidden from you and is of little use to you, as all the access methods \"abstract\" the details of the computer hardware away, allowing the programmer to concentrate on the algorithm, and not the details.</p>\n</li>\n<li>\n<p>Arrays variables simply contain the address of the first element of the array. Arrays are zero based so the address simply becomes the base address plus the index.</p>\n</li>\n<li>\n<p>Structure variables simply contain the address of the first element of the structure, and each \"named\" field of the structure forms an offset from the first bucket. The computer keeps track of this offset so that the programmer can use symbolic names instead of numbers.</p>\n</li>\n<li>\n<p>Memory buckets are 8 bits long (or one byte). A character (char) is one byte. An integer is (usually) four bytes. A float is four bytes. A double is 8 bytes.</p>\n</li>\n</ol>\n<h3 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Performance</strong></h3>\n<p>It conclude on the basis of time/memory/disk/etc. usage when we run the code. It depends on the machine, compiler, OS, etc as well as the code itself.</p>\n<h3 id=\"complexity\" style=\"position:relative;\"><a href=\"#complexity\" aria-label=\"complexity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Complexity</strong></h3>\n<p>We are typically interested in the execution time of large instances of a problem, e.g., when ùëõ ‚Üí ‚àû, (asymptotic complexity). <em>for this we introduce the big O notation.</em></p>\n<p><strong>Big O notation</strong> is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. big O notation is used to classify algorithms according to how their run time or space requirements grow as the input size grows. In analytic number theory, big O notation is often used to express a bound on the difference between an arithmetical function and a better understood approximation. Big O notation characterizes functions according to their growth rates: different functions with the same growth rate may be represented using the same O notation. The letter O is used because the growth rate of a function is also referred to as the <strong>order of the function</strong>. A description of a function in terms of big O notation usually only provides an upper bound on the growth rate of the function.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Function</th>\n<th align=\"center\">common name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">N!</td>\n<td align=\"center\">factorial</td>\n</tr>\n<tr>\n<td align=\"center\">2^n</td>\n<td align=\"center\">exponential</td>\n</tr>\n<tr>\n<td align=\"center\">n¬≥</td>\n<td align=\"center\">cubic</td>\n</tr>\n<tr>\n<td align=\"center\">n¬≤</td>\n<td align=\"center\">quadratic</td>\n</tr>\n<tr>\n<td align=\"center\">n log n</td>\n<td align=\"center\">quasi-linear</td>\n</tr>\n<tr>\n<td align=\"center\">n</td>\n<td align=\"center\">linear</td>\n</tr>\n<tr>\n<td align=\"center\">log n</td>\n<td align=\"center\">logarithmic</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">constant</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"different-types-of-complexity\" style=\"position:relative;\"><a href=\"#different-types-of-complexity\" aria-label=\"different types of complexity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Different types of complexity</h2>\n<p>There are several different types of complexities , we will only be looking into the more popular and the most commonly used ones.</p>\n<h3 id=\"constant-time-complexity-o1\" style=\"position:relative;\"><a href=\"#constant-time-complexity-o1\" aria-label=\"constant time complexity o1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Constant Time Complexity: O(1)</h3>\n<p>Complexity <strong>O(1)</strong> is the best, it‚Äôs not always achievable, but if it is, then your code is <em>independent</em> of the input size.</p>\n<p>Other operations that have complexity <strong>O(1)</strong> are the print function, simple arithmetic ‚Äî addition, subtraction, and multiplication and division in the case of integers.</p>\n<h3 id=\"linear-time-complexity-on\" style=\"position:relative;\"><a href=\"#linear-time-complexity-on\" aria-label=\"linear time complexity on permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Linear Time Complexity: O(n)</h3>\n<p>When time complexity grows in direct proportion to the size of the input, you are facing Linear Time Complexity, or O(n). Algorithms with this time complexity will process the input (n) in ‚Äún‚Äù number of operations. This means that as the input grows, the algorithm takes proportionally longer to complete.</p>\n<p>Linear running time algorithms are very common, and they relate to the fact that the algorithm visits every element from the input.</p>\n<h3 id=\"logarithmic-time-complexity-olog-n\" style=\"position:relative;\"><a href=\"#logarithmic-time-complexity-olog-n\" aria-label=\"logarithmic time complexity olog n permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Logarithmic Time Complexity: O(log n)</h3>\n<p>Algorithms with this complexity make computation amazingly fast. An algorithm is said to run in logarithmic time if its time execution is proportional to the logarithm of the input size. This means that instead of increasing the time it takes to perform each subsequent step, the time is decreased at a magnitude that is inversely proportional to the input ‚Äún‚Äù.</p>\n<h3 id=\"quadratic-time-complexity-on¬≤\" style=\"position:relative;\"><a href=\"#quadratic-time-complexity-on%C2%B2\" aria-label=\"quadratic time complexity on¬≤ permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Quadratic Time Complexity: O(n¬≤)</h3>\n<p>In this type of algorithms, the time it takes to run grows directly proportional to the square of the size of the input (like linear, but squared).</p>\n<p>Nested <strong>For Loops</strong> run on quadratic time, because you‚Äôre running a linear operation within another linear operation, or <em>n</em> which equals <em>n¬≤.</em></p>\n<p>If you face these types of algorithms, you‚Äôll either need a lot of resources and time, or you‚Äôll need to come up with a better algorithm.</p>\n<h3 id=\"on-logn\" style=\"position:relative;\"><a href=\"#on-logn\" aria-label=\"on logn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>O(n log(n))</h3>\n<p>If we have a code or an algorithm with complexity <strong>O(log(n))</strong> that gets repeated multiple times, then it becomes <strong>O(n log(n))</strong>. Famous examples of this are <strong>merge sort and quicksort</strong>.</p>\n<h1 id=\"big-o-rules\" style=\"position:relative;\"><a href=\"#big-o-rules\" aria-label=\"big o rules permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Big O rules</h1>\n<p>Going through the above examples, you might have figured out some rules for calculating Big O, but let‚Äôs sum them up:</p>\n<ol>\n<li>Reading, writing an item in a list or a dictionary has <strong>O(1)</strong>.</li>\n<li>Going through an iterable is <strong>O(n)</strong>.</li>\n<li>Nested loops lead to <strong>O(n¬≤)</strong> complexity.</li>\n<li>Any divide and concur approach or loops handling binary numbers have <strong>O(n log(n))</strong> complexity.</li>\n<li>We sum up the complexity of sequential loops and multiply the complexity of nested loops.</li>\n</ol>","frontmatter":{"path":"/intro-complexity","title":"Complexity Analysis","order":"7A","section":"Space & Time Complexity"}},"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"order":"4B","path":"/arraylist","title":"ArrayList In Java"}}},{"node":{"frontmatter":{"order":"24A","path":"/assignment","title":"Assignments"}}},{"node":{"frontmatter":{"order":"4A","path":"/arrays","title":"Introduction to Arrays"}}},{"node":{"frontmatter":{"order":"9E","path":"/backtrack-maze","title":"Maze Problems"}}},{"node":{"frontmatter":{"order":"9D","path":"/backtrack-nknight","title":"N Knights"}}},{"node":{"frontmatter":{"order":"9B","path":"/backtrack-sudoku","title":"Sudoku Solver"}}},{"node":{"frontmatter":{"order":"9A","path":"/backtracking","title":"Introduction to Backtracking"}}},{"node":{"frontmatter":{"order":"5B","path":"/binarysearch","title":"Binary Search"}}},{"node":{"frontmatter":{"order":"10B","path":"/bitwise-operator","title":"Complete Bitwise Operators"}}},{"node":{"frontmatter":{"order":"4D","path":"/bmmv-algorithm","title":"Boyer-Moore Majority Voting Algorithm"}}},{"node":{"frontmatter":{"order":"9C","path":"/backtrack-nqueen","title":"N Queens"}}},{"node":{"frontmatter":{"order":"5C","path":"/bubblesort","title":"Bubble Sort"}}},{"node":{"frontmatter":{"order":"5F","path":"/countsort","title":"Count Sort"}}},{"node":{"frontmatter":{"order":"5H","path":"/cyclesort","title":"Cyclic Sort"}}},{"node":{"frontmatter":{"order":"3A","path":"/dataTypes","title":"Learn Data Types"}}},{"node":{"frontmatter":{"order":"2C","path":"/firstjavaprogram","title":"First Java Program"}}},{"node":{"frontmatter":{"order":"8B","path":"/flow-of-recursion","title":"Flow of Recursion"}}},{"node":{"frontmatter":{"order":"2A","path":"/flowchart","title":"Flowchart & Pseudocode"}}},{"node":{"frontmatter":{"order":"3F","path":"/functions","title":"Function & Scope"}}},{"node":{"frontmatter":{"order":"20A","path":"/greedy","title":"Introduction to Greedy Algorithms"}}},{"node":{"frontmatter":{"order":"5E","path":"/insertion","title":"Insertion Sort"}}},{"node":{"frontmatter":{"order":"15A","path":"/intro-binarytree","title":"Intro to Binary Tree"}}},{"node":{"frontmatter":{"order":"16A","path":"/intro-bst","title":"Intro to BST"}}},{"node":{"frontmatter":{"order":"7A","path":"/intro-complexity","title":"Complexity Analysis"}}},{"node":{"frontmatter":{"order":"19A","path":"/intro-dp","title":"Introduction to DP"}}},{"node":{"frontmatter":{"order":"12A","path":"/intro-ds","title":"Introduction to Data Structures"}}},{"node":{"frontmatter":{"order":"22A","path":"/intro-graphs","title":"Introduction to Graphs"}}},{"node":{"frontmatter":{"order":"18A","path":"/intro-hashmap","title":"Introduction to Hashmap"}}},{"node":{"frontmatter":{"order":"17A","path":"/intro-heap","title":"Introduction to Heaps"}}},{"node":{"frontmatter":{"order":"12B","path":"/intro-linkedlist","title":"Introduction to Linked List"}}},{"node":{"frontmatter":{"order":"10A","path":"/intro-maths","title":"Introduction to Maths in DSA"}}},{"node":{"frontmatter":{"order":"11A","path":"/intro-oop","title":"Introduction"}}},{"node":{"frontmatter":{"order":"21A","path":"/intro-priorityqueues","title":"Introduction to Priority Queues"}}},{"node":{"frontmatter":{"order":"1B","path":"/intro-programming","title":"Intro to Programming"}}},{"node":{"frontmatter":{"order":"8A","path":"/intro-recursion","title":"Intro to Recursion"}}},{"node":{"frontmatter":{"order":"13A","path":"/intro-stacks","title":"Intro to Stack"}}},{"node":{"frontmatter":{"order":"6A","path":"/intro-string","title":"Intro to Strings"}}},{"node":{"frontmatter":{"order":"14A","path":"/intro-trees","title":"Intro to Trees"}}},{"node":{"frontmatter":{"order":"23A","path":"/intro-tries","title":"Introduction to Tries"}}},{"node":{"frontmatter":{"order":"1A","path":"/introduction","title":"Welcome"}}},{"node":{"frontmatter":{"order":"3C","path":"/io-conditionals","title":"Input/Output & Conditionals"}}},{"node":{"frontmatter":{"order":"4F","path":"/jagged-array","title":"Jagged Arrays"}}},{"node":{"frontmatter":{"order":"2B","path":"/java-setup","title":"Java Development Setup"}}},{"node":{"frontmatter":{"order":"3E","path":"/jumps","title":"Jumps Statements"}}},{"node":{"frontmatter":{"order":"5A","path":"/linearsearch","title":"Linear Search"}}},{"node":{"frontmatter":{"order":"3D","path":"/loops","title":"Loops In Java"}}},{"node":{"frontmatter":{"order":"8E","path":"/mergesort","title":"Merge Sort"}}},{"node":{"frontmatter":{"order":"10C","path":"/num-one","title":"Number Theory Part-A"}}},{"node":{"frontmatter":{"order":"10E","path":"/num-three","title":"Number Theory Part-C"}}},{"node":{"frontmatter":{"order":"10D","path":"/num-two","title":"Number Theory Part-B"}}},{"node":{"frontmatter":{"order":"3B","path":"/operators","title":"Operators in Java"}}},{"node":{"frontmatter":{"order":"5I","path":"/practise-question","title":"Practise Questions"}}},{"node":{"frontmatter":{"order":"4C","path":"/print-patterns","title":"Printing Patterns"}}},{"node":{"frontmatter":{"order":"11C","path":"/properties","title":"Properties of OOP"}}},{"node":{"frontmatter":{"order":"8F","path":"/quicksort","title":"Quick Sort"}}},{"node":{"frontmatter":{"order":"5G","path":"/radixsort","title":"Radix Sort"}}},{"node":{"frontmatter":{"order":"7D","path":"/recurrence","title":"Recurrence Relations"}}},{"node":{"frontmatter":{"order":"8C","path":"/recursion-arrays","title":"Recursion & Array"}}},{"node":{"frontmatter":{"order":"8G","path":"/recursion-practise","title":"Standard Practise Questions"}}},{"node":{"frontmatter":{"order":"8D","path":"/recursion-string","title":"Recursion & Strings"}}},{"node":{"frontmatter":{"order":"5D","path":"/selectionsort","title":"Selection Sort"}}},{"node":{"frontmatter":{"order":"7C","path":"/space-complexity","title":"Space Complexity"}}},{"node":{"frontmatter":{"order":"6B","path":"/string-builder","title":"StringBuilder in Java"}}},{"node":{"frontmatter":{"order":"4E","path":"/subarrays","title":"Subarrays"}}},{"node":{"frontmatter":{"order":"11B","path":"/this-constructor","title":"this Keyword & Constructor"}}},{"node":{"frontmatter":{"order":"7B","path":"/time-complexity","title":"Time Complexity"}}},{"node":{"frontmatter":{"order":"7E","path":"/time_space_tradeoff","title":"Time Space Tradeoff"}}}]}},"pageContext":{}},"staticQueryHashes":["137611351"]}